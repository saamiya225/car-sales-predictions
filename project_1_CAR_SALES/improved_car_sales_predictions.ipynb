{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6d39eb6",
   "metadata": {},
   "source": [
    "# Car Sales Prediction Model\n",
    "This notebook contains an improved version of the original car sales prediction model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614c83be",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, BatchNormalization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86af4f0c",
   "metadata": {},
   "source": [
    "## Load Dataset and Perform Basic Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984c7b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load dataset\n",
    "car_df = pd.read_csv('Car_Purchasing_Data.csv', encoding='ISO-8859-1')\n",
    "\n",
    "# Data Exploration\n",
    "print(car_df.info())\n",
    "print(car_df.describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311efe50",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00adbb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Drop irrelevant columns\n",
    "X = car_df.drop(['Customer Name', 'Customer e-mail', 'Country', 'Car Purchase Amount'], axis=1)\n",
    "y = car_df['Car Purchase Amount'].values.reshape(-1, 1)\n",
    "\n",
    "# Check for missing values\n",
    "print(\"Missing Values:\\n\", car_df.isnull().sum())\n",
    "\n",
    "# Feature Scaling\n",
    "scaler_X = MinMaxScaler()\n",
    "X_scaled = scaler_X.fit_transform(X)\n",
    "\n",
    "scaler_y = MinMaxScaler()\n",
    "y_scaled = scaler_y.fit_transform(y)\n",
    "\n",
    "# Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size=0.25, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4845981",
   "metadata": {},
   "source": [
    "## Build and Train Improved Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf375c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Build Improved Neural Network\n",
    "model = Sequential([\n",
    "    Dense(64, input_dim=X_train.shape[1], activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(1, activation='linear')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train Model\n",
    "history = model.fit(X_train, y_train, epochs=200, batch_size=32, validation_split=0.2, verbose=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b0953d",
   "metadata": {},
   "source": [
    "## Plot Training Loss Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bead710",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot Loss Curve\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.title(\"Loss Curve\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5776208",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab976fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Model Evaluation\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = scaler_y.inverse_transform(y_pred)  # Convert back to original scale\n",
    "y_test = scaler_y.inverse_transform(y_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"MAE: {mae:.2f}, RMSE: {rmse:.2f}, RÂ² Score: {r2:.2f}\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}